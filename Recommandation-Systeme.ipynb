{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFT 599/799 – Science des données\n",
    "\n",
    "## TP4 :  Recommandation par filtarge collaboratif\n",
    "\n",
    "Ce TP porte sur le développement d'une application du filtrage collaboratif pour construire un\n",
    "système de recommandation. Les données à utiliser sont celles fournies par le MovieLens\n",
    "100K. Le but de ce TP est de se familliariser avec une méthode de recommandation de base et la méthode de crossvalidation pour évaluer la performance d’un système d’apprentissage.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dans un premier temps, il est nécessaire d'importer les différente librairies utilisées\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction : Compréhension des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>nknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id        movie_title release_date  nknown  Action  Adventure  \\\n",
       "0         1   Toy Story (1995)  01-Jan-1995       0       0          0   \n",
       "1         2   GoldenEye (1995)  01-Jan-1995       0       1          1   \n",
       "2         3  Four Rooms (1995)  01-Jan-1995       0       0          0   \n",
       "\n",
       "   Animation  Children's  Comedy  Crime  ...  Fantasy  Film-Noir  Horror  \\\n",
       "0          1           1       1      0  ...        0          0       0   \n",
       "1          0           0       0      0  ...        0          0       0   \n",
       "2          0           0       0      0  ...        0          0       0   \n",
       "\n",
       "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0        0       0         0    0        0  \n",
       "1        0        0        0       0         1    0        0  \n",
       "2        0        0        0       0         1    0        0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afin de comprendre mieux nos données, on regarde movieLens-Dataset\n",
    "data_path = 'MovieLens-Dataset/ml-100K/'\n",
    "columns = ['movie_id','movie_title','release_date','video_release_date','IMDb_URL',\n",
    "           'nknown','Action','Adventure','Animation','Children\\'s','Comedy','Crime','Documentary',\n",
    "           'Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi',\n",
    "           'Thriller','War','Western']\n",
    "u_item = pd.read_csv(os.path.join(data_path, 'u_item.csv'), \n",
    "                     sep='|', encoding='latin-1', names=columns).drop(\n",
    "                    labels=['IMDb_URL', 'video_release_date'], axis=1)\n",
    "u_item.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remaque qu'un item possède 22 caractéristiques, à savoir son titre, sa date de sortie, mais également, sous la forme d'un \"one-hot\" vector, le type de film dont il s'agit, qui peut être :'unknown','Action','Adventure','Animation','Children\\'s','Comedy','Crime','Documentary',\n",
    "           'Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi',\n",
    "           'Thriller','War' ou'Western'. Nous ne nous servirons pas de ce jeu de données à la suite de ce TP, il nous sert uniquement à comprendre ce que contient le dataset de l'exercice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25741</th>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93639</th>\n",
       "      <td>806</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55726</th>\n",
       "      <td>768</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49529</th>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89079</th>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80525</th>\n",
       "      <td>403</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14401</th>\n",
       "      <td>322</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99282</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35188</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29031</th>\n",
       "      <td>514</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating\n",
       "25741       84        1       2\n",
       "93639      806        1       4\n",
       "55726      768        1       5\n",
       "49529       92        1       4\n",
       "89079      419        1       4\n",
       "80525      403        1       4\n",
       "14401      322        1       2\n",
       "99282      709        1       4\n",
       "35188      120        1       4\n",
       "29031      514        1       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Désormais on regarde les données de notation\n",
    "u_data = pd.read_csv(os.path.join(data_path, 'u_data.csv'), \n",
    "                     sep='\t', header=None, \n",
    "                     names=['user_id','item_id','rating','timestamp'])\n",
    "# On supprime la caractéristique \"timestamp\" qui ne nous apporte pas d'informations\n",
    "# pour la recommandation\n",
    "u_data = u_data.drop(labels=['timestamp'], axis=1).sort_values('item_id')\n",
    "u_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que nos données, après avoir supprimé la caractéristique \"timestamp\", comprend l'id d'un utilisateur, l'item que cet utilisateur a considéré et la note associée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Système de recommandation en se basant sur la méthode par voisinage\n",
    "\n",
    "Nous avons effectué le choix pour ce TP de développer un système de recommandation basé sur la méthode par voisinage, qui consiste à choisir les k voisins d'un utilisateur et de considérer la moyenne de la note donnée par ces voisins sur un item. Une première fonction permet le calcul des moyennes et écart-types des notes données par chaque utilisateur. Cela sera très utile pour la prédiction de la note finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afin d'augmenter la vitesse de calcul, on créé un nouveau dataframe contenant: \n",
    "# id_user, note_moyenne_donnée, écart-type des notes données\n",
    "def get_u_ids(u_data):\n",
    "    u_ids = u_data.drop_duplicates('user_id', keep='first')\n",
    "    mean = []\n",
    "    std = []\n",
    "    for index, row in u_ids.iterrows():\n",
    "        mean.append(u_data[u_data['user_id']==row['user_id']].mean(axis=0)['rating'])\n",
    "        std.append(u_data[u_data['user_id']==row['user_id']].std(axis=0)['rating'])\n",
    "    u_ids.insert(1, \"std\", std)\n",
    "    u_ids.insert(1, \"mean\", mean)\n",
    "    u_ids = u_ids.drop(labels=['item_id','rating'], axis=1)\n",
    "    return u_ids\n",
    "u_ids = get_u_ids(u_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 individus ont déjà voté pour ce film\n",
      "Après calcul des similitudes, on ne conserve que 23 candidats.\n",
      "Puis les k=20 voisins les plus proches sont finalement conservées\n",
      "L'utilisateur 276 a voté [3] pour cet item, sa similitude est 0.34158468920776675.\n",
      "L'utilisateur 43 a voté [4] pour cet item, sa similitude est 0.34257829469755874.\n",
      "L'utilisateur 378 a voté [3] pour cet item, sa similitude est 0.3597051434745263.\n",
      "L'utilisateur 280 a voté [4] pour cet item, sa similitude est 0.38944863236080846.\n",
      "L'utilisateur 864 a voté [4] pour cet item, sa similitude est 0.4009338683510621.\n",
      "L'utilisateur 393 a voté [3] pour cet item, sa similitude est 0.42148267966859826.\n",
      "L'utilisateur 255 a voté [2] pour cet item, sa similitude est 0.4389479684796693.\n",
      "L'utilisateur 880 a voté [3] pour cet item, sa similitude est 0.45497065785967955.\n",
      "L'utilisateur 311 a voté [3] pour cet item, sa similitude est 0.4586285569750353.\n",
      "L'utilisateur 109 a voté [3] pour cet item, sa similitude est 0.48764935757562383.\n",
      "L'utilisateur 709 a voté [4] pour cet item, sa similitude est 0.4927692111216915.\n",
      "L'utilisateur 303 a voté [2] pour cet item, sa similitude est 0.49864691389691806.\n",
      "L'utilisateur 643 a voté [3] pour cet item, sa similitude est 0.5.\n",
      "L'utilisateur 28 a voté [3] pour cet item, sa similitude est 0.5127954669727754.\n",
      "L'utilisateur 593 a voté [4] pour cet item, sa similitude est 0.5535115773725051.\n",
      "L'utilisateur 92 a voté [4] pour cet item, sa similitude est 0.5578217116404051.\n",
      "L'utilisateur 291 a voté [5] pour cet item, sa similitude est 0.5720539055840977.\n",
      "L'utilisateur 399 a voté [3] pour cet item, sa similitude est 0.6532425407273184.\n",
      "L'utilisateur 422 a voté [3] pour cet item, sa similitude est 0.7081237603984349.\n",
      "L'utilisateur 671 a voté [2] pour cet item, sa similitude est 0.9138311535740187.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.05501194])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pearson_correlation(id_indiv_1, id_indiv_2, u_data, gamma):\n",
    "    # On cherche quels items ont été noté par les 2 personnes:\n",
    "    indiv_1 = u_data['user_id'] == id_indiv_1\n",
    "    indiv_2 = u_data['user_id'] == id_indiv_2\n",
    "    filter_indiv = ( indiv_1 | indiv_2 ) \n",
    "    df_individus = u_data[filter_indiv]\n",
    "    items_in_common = df_individus[df_individus.duplicated('item_id',keep=False)]\n",
    "    if items_in_common.empty:\n",
    "        return 0\n",
    "    else:\n",
    "        mean_rate_1 = df_individus[df_individus['user_id']==id_indiv_1].mean(axis=0)['rating']\n",
    "        mean_rate_2 = df_individus[df_individus['user_id']==id_indiv_2].mean(axis=0)['rating']\n",
    "        kept_items_1 = np.squeeze(items_in_common[indiv_1].to_numpy()[:, -1:])\n",
    "        kept_items_2 = np.squeeze(items_in_common[indiv_2].to_numpy()[:, -1:])\n",
    "        norm_1 = kept_items_1-mean_rate_1\n",
    "        norm_2 = kept_items_2-mean_rate_2\n",
    "        denom = np.sqrt((np.sum((norm_1)**2))*np.sum(((norm_2)**2))) \n",
    "        if denom == 0:\n",
    "            pc = 0\n",
    "        else:\n",
    "            pc = np.sum((norm_1)*(norm_2)) / np.sqrt((np.sum((norm_1)**2))*np.sum(((norm_2)**2)))\n",
    "            pc *= min([kept_items_1.size, gamma]) / gamma\n",
    "        return pc\n",
    "    \n",
    "def find_neighboors_id(u_data, u_ids, indiv_id, k, w_min, item, gamma=4, verbose=False):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    u_data: (dataframe) contenant l'ensemble des données ('user_id', 'item_id', 'rating')\n",
    "    u_ids: (data_frame) contenant des données propres à chaque utilisateur ('user_id', 'mean_rate', 'std_rate')\n",
    "    indiv_id: (int) contenant l'id de l'individu dont on veut prédire la note\n",
    "    k: (int) nomnbre de candidats sur lesquels se baser pour la prédiction\n",
    "    w_min: (float) similitude minimale pour estimer un candidat comme voisin potentiel\n",
    "    item: (int) contenant l'id de l'item dont on souhaite prédire la note\n",
    "    gamma: (int) nombre de films minimal en commun sinon une penalité s'applique sur la similitude\n",
    "    Returns:\n",
    "    float: note prédite\n",
    "    \"\"\"\n",
    "    # Avant de supprimer notre individu on récupère sa note moyenne et son écart-type :\n",
    "    mean_user_rate = u_ids[u_ids['user_id']==indiv_id]['mean'].to_numpy()\n",
    "    std_user_rate = u_ids[u_ids['user_id']==indiv_id]['std'].to_numpy()\n",
    "    # On créée le dataframe des users ayant déjà noté le film: \n",
    "    # Cela permet d'accelerer les calculs (l'algo étant au minima linéaire en le nombre de données)\n",
    "    u_item = u_data[u_data['item_id']==item].drop_duplicates('user_id', keep='first')['user_id']\n",
    "    if verbose : \n",
    "        print(\"{} individus ont déjà voté pour ce film\".format(len(u_item)))\n",
    "    # Afin de limiter le nombre de variables on utilise ce même tableau pour conserver tous les utilisateurs :\n",
    "    u_ids.insert(3,\"is_in\",list(u_ids['user_id'].isin(u_item)))\n",
    "    # On supprime du dataframe notre utilisateur et les utilisateurs n'ayant pas voté pour le film::\n",
    "    df = u_ids[(u_ids['user_id']!=indiv_id) & (u_ids['is_in']==True)]\n",
    "    pc = []\n",
    "    for index, row in df.iterrows():\n",
    "        pc.append(pearson_correlation(indiv_id, row['user_id'], u_data, gamma))\n",
    "    # Conversion de df vers un numpy pour utiliser les bonnes propriétés de mask:\n",
    "    df = df['user_id'].to_numpy()\n",
    "    pc = np.array(pc)\n",
    "    # On ne conserve que les voisins ayant la similitude supérieure au seuil:\n",
    "    mask = pc > 0.3\n",
    "    res = np.array([df[mask], pc[mask]])\n",
    "    # On trie les voisins selon leur similitude croissante\n",
    "    knn = res.T[res.T[:,1].argsort()]\n",
    "    if verbose: \n",
    "        print(\"Après calcul des similitudes, on ne conserve que {} candidats.\".format(len(knn)))\n",
    "        print(\"Puis les k={} voisins les plus proches sont finalement conservées\".format(k))\n",
    "    # On ne conserve que les k plus proches\n",
    "    if k < knn.shape[0]:\n",
    "        knn = knn[len(knn)-k:, :]\n",
    "    if len(knn) == 0:\n",
    "        u_ids = u_ids.drop(columns='is_in', inplace=False)\n",
    "        return -1, u_ids\n",
    "    # On effectue la prédiction sur les k plus proches\n",
    "    denom = np.sum(np.abs(knn[:, 1]))\n",
    "    rate_pred = 0\n",
    "    for elt in knn:\n",
    "        note_v = u_data[(u_data['user_id']==int(elt[0]))&(u_data['item_id']==item)]['rating'].values\n",
    "        if verbose:\n",
    "            print(\"L'utilisateur {} a voté {} pour cet item, sa similitude est {}.\". \\\n",
    "                  format(int(elt[0]), note_v, elt[1]))\n",
    "        user_v_mean = u_ids[u_ids['user_id']==int(elt[0])]['mean'].to_numpy()\n",
    "        std_v_mean = u_ids[u_ids['user_id']==int(elt[0])]['std'].to_numpy()\n",
    "        rate_pred += elt[1] * (note_v - user_v_mean) / std_v_mean\n",
    "    rate_pred = rate_pred / denom\n",
    "    rate_pred = mean_user_rate + std_user_rate*rate_pred\n",
    "    # Pour une réutilisation du dataframe, on supprime la colonne spécifique à l'item:\n",
    "    u_ids = u_ids.drop(columns='is_in', inplace=False)\n",
    "    return rate_pred, u_ids\n",
    "\n",
    "res, u_ids = find_neighboors_id(u_data, u_ids, 78, k=20, w_min=10, item=5, verbose=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessus est un exemple de sortie de l'algorithme implémenté : le nombre d'individus ayant voté pour cet item, le nombre de candidat retenu, la note effectuée par ce candidat pour cet item mais également la similitude entre ce candidat et le candidat pour qui on souhaite faire la recommandation. Finalement, l'algorithme retourne la note qui pourrait être attribuée à cet item par ce candidat, ici 3,05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du système\n",
    "\n",
    "Dans un second temps, nous souhaitons tester le système de recommandation sur cinq bases de données différentes. Nous avons pris la décision de ne conserver que les 100 premiers objets de chacune des bases de données de test afin de réduire considérablement les temps de calculs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour ne pas afficher une cellule remplie d'import, l'ensemble des manipulations d'ouverture / traitement a été \n",
    "# effectué dans un script externe\n",
    "from import_validation_data import u1_base, u2_base, u3_base, u4_base, u5_base, \\\n",
    "                                   u1_test, u2_test, u3_test, u4_test, u5_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(base, test):\n",
    "    \"\"\"\n",
    "    Fonction qui permet, grâce aux algorithmes précédents de calculer\n",
    "    l'erreur effectuée par l'algorithme sur une base de données de test\n",
    "    \"\"\"\n",
    "    u_ids = get_u_ids(base)\n",
    "    error = 0\n",
    "    for index, row in test.iterrows():\n",
    "        res, u_ids = find_neighboors_id(base, u_ids, indiv_id=row['user_id'], k=20, w_min=10, \n",
    "                                        item=row['item_id'],verbose=False)\n",
    "        if res != -1:\n",
    "            error = error + np.abs(res - row['rating'])\n",
    "    error = error / test.shape[0]\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur sur jeu 1: [0.71692126]\n",
      "Temps écoulé: 85.22398400306702\n",
      "erreur sur jeu 2: [0.8415115]\n",
      "Temps écoulé: 184.64445996284485\n",
      "erreur sur jeu 3: [0.80086194]\n",
      "Temps écoulé: 280.69833302497864\n",
      "erreur sur jeu 4: [0.7829049]\n",
      "Temps écoulé: 359.84035301208496\n",
      "erreur sur jeu 5: [0.81823037]\n",
      "Temps écoulé: 449.34778094291687\n",
      "Erreur moyenne: [0.79208599]\n",
      "Temps total 449.3481719493866\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "top = time()\n",
    "err1 = get_error(u1_base, u1_test[:100])\n",
    "print(\"Erreur sur jeu 1: {}\".format(err1))\n",
    "print(\"Temps écoulé: {}\".format(abs(time()-top)))\n",
    "err2 = get_error(u2_base, u2_test[:100])\n",
    "print(\"erreur sur jeu 2: {}\".format(err2))\n",
    "print(\"Temps écoulé: {}\".format(abs(time()-top)))\n",
    "err3 = get_error(u3_base, u3_test[:100])\n",
    "print(\"erreur sur jeu 3: {}\".format(err3))\n",
    "print(\"Temps écoulé: {}\".format(abs(time()-top)))\n",
    "err4 = get_error(u4_base, u4_test[:100])\n",
    "print(\"erreur sur jeu 4: {}\".format(err4))\n",
    "print(\"Temps écoulé: {}\".format(abs(time()-top)))\n",
    "err5 = get_error(u5_base, u5_test[:100])\n",
    "print(\"erreur sur jeu 5: {}\".format(err5))\n",
    "print(\"Temps écoulé: {}\".format(abs(time()-top)))\n",
    "mean_err = (err1 + err2 + err3 + err4 + err5)/5\n",
    "print(\"Erreur moyenne: {}\".format(mean_err))\n",
    "print(\"Temps total {}\".format(abs(time()-top)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, on remarque que l'erreur moyenne de l'algorithme sur l'ensemble des jeux de test est de 0.79. La note finale étant normalement un entier on pourrait donc qualifier notre incertitude de prédiction à plus ou moins 1.  \n",
    "Ces résultats ne sont pas parfaits car il existe des hyperparamètres à optimiser: nombre de candidats à retenir pour la prédiction, nombre de films minimal en commun n'entraînant pas une pénalité de la similitude ou encore seuil de similitude minimal pour le préfiltrage des candidats. Ajoutons aussi que cette méthode pourrait être améliorée en ajoutant d'autre stratégies (comme par exemple un item-based model) et en faisant \"voter\" ces stratégies pour une note finale (stratégie de bagging)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
